<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Quentin BERTRAND - Home</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Quentin BERTRAND</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="https://github.com/qb3">Github</a></div>
<div class="menu-item"><a href="optim_crash_course.html">Optim&nbsp;Crash&nbsp;Course</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Quentin BERTRAND - Home</h1>
</div>
<table class="imgtable"><tr><td>
<img src="./london_cropped.png" alt="Picture of me" width="207px" height="194px" />&nbsp;</td>
<td align="left"><p>Since July 1st, I am a researcher (&lsquo;charg√© de recherche&lsquo;) at Inria Lyon, located in Laboratoire Hubert Curien.
I work on optimization, games, and representation learning.</p>
<p>From November 2021 to June 204, I was a post-doctoral researcher at <a href="https://mila.quebec/">Mila</a> working with <a href="https://gauthiergidel.github.io/">Gauthier Gidel</a> and <a href="https://www.iro.umontreal.ca/~slacoste/">Simon Lacoste-Julien</a>.
<br />
Prior to this position, I did my Ph. D. at Inria Paris-Saclay
(in the <a href="https://team.inria.fr/parietal/">Parietal Team</a>) under the supervision of <a href="https://josephsalmon.eu/">Joseph Salmon</a> and <a href="http://alexandre.gramfort.net/">Alexandre Gramfort</a>.
<br />
I worked on the optimization and statistical aspects of high dimensional sparse linear regression applied to brain signal reconstruction.
<br />
In particular, I developed Python packages for fast <a href="https://github.com/scikit-learn-contrib/skglm">computation</a> and <a href="https://github.com/QB3/sparse-ho">automatic hyperparameter selection</a> of sparse linear models.</p>
<p><br />
Here is a short <a href="./pdfs/Quentin_BERTRAND_CV.pdf">resume</a> and my <a href="research.html">list of publications</a>.</p>
</td></tr></table>
<h2>Contact</h2>
<div class="infoblock">
<div class="blockcontent">
<p>Email: quentin [dot] bertrand AT mila [dot] quebec<br /></p>
</div></div>
<h2>News</h2>
<ul>
<li><p>04-22-2024 The recording of the talk <a href="https://arxiv.org/pdf/2310.00429.pdf,">On the Stability of Iterative Retraining of Generative Models on their own Data</a> at the Montreal Machine Learning Seminar can be found <a href="https://www.youtube.com/watch?v=ZOLHzmSZWrA">here</a></p>
</li>
<li><p>01-16-2024 Our paper <a href="https://arxiv.org/pdf/2310.00429.pdf,">On the Stability of Iterative Retraining of Generative Models on their own Data</a> was accepted to ICLR 2024 with a spotlight, see you in Vienna!</p>
</li>
<li><p>12-18-2023 We just released our paper proving that <a href="https://arxiv.org/abs/2312.08484">Q-learners can provably learn to collude in the iterated prisoner dilemma</a>!</p>
</li>
<li><p>01-07-2023 On July 1st, 2024 I will join Inria as a Research Scientist!</p>
</li>
</ul>
<h2>Previous News</h2>
<ul>
<li><p>05-12-2023 I will present our paper <a href="https://arxiv.org/pdf/2206.12301.pdf,">On the Limitations of Elo: Real-World Games are Transitive, not Additive</a> at the <a href="https://sites.google.com/view/berkeleymarl/home">Berkeley Multi-Agent Reinforcement Learning Seminar</a></p>
</li>
<li><p>Our paper <a href="https://arxiv.org/abs/2211.14666">Synergies between Disentanglement and Sparsity:
Generalization and Identifiability in Multi-Task Learning</a> has been accepted at ICML 2023, see you in Hawaii!</p>
</li>
<li><p>Our paper <a href="https://arxiv.org/pdf/2206.12301.pdf,">On the Limitations of Elo: Real-World Games are Transitive, not Additive</a> has been accepted to AISTATS 2023, see you in Spain!</p>
</li>
<li><p>I just presented our paper <a href="https://arxiv.org/abs/2211.14666">Synergies between Disentanglement and Sparsity: a Multi-task Learning Perspective</a> at the <a href="https://winter22.cms.math.ca/">Canadian Mathematical Society Winter Workshop</a></p>
</li>
<li><p>I just presented our two papers <a href="https://arxiv.org/pdf/2204.07826.pdf">Beyond L1: Faster and Better Sparse Models with skglm</a> and <a href="https://arxiv.org/abs/2209.13271">The Curse of Unrolling: Rate of Differentiating Through Optimization</a> at NeurIPS 2022</p>
</li>
<li><p>I was awarded the <a href="https://neurips.cc/Conferences/2022/ProgramCommittee">top reviewer award</a> at NeurIPS 2022!</p>
</li>
<li><p>Our papers <a href="https://arxiv.org/pdf/2204.07826.pdf">Beyond L1: Faster and Better Sparse Models with skglm</a> and <a href="https://arxiv.org/abs/2209.13271">The Curse of Unrolling: Rate of Differentiating Through Optimization</a> have been accepted to NeurIPS 2022!</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
