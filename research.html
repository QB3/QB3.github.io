  <!doctype html>
  <html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\(','$\)']],
      displayMath: [['$$','$$'], ['$\[','$\]']]
    },
    TeX: {
      extensions: ["AMScd.js", "action.js", "autobold.js", "cancel.js", "begingroup.js", "color.js", "enclose.js"]
    }
  });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="jemdoc.css" type="text/css" />
  <title>Quentin BERTRAND - Research</title>
  </head>
  <body>
  <div class="title-divider"></div>
  <main class="container" id="tlayout">
  <div class="row">
  <!-- Side menu -->
  <aside class="col-12 col-md-3 " id="sidemenu">
  <ul class="nav nav-pills flex-column">
  <div class="menu-category">Quentin BERTRAND</div>
  <li class="nav-item menu-item"><a href="index.html" class="nav-link">Home</a></li>
  <li class="nav-item menu-item"><a href="research.html" class="nav-link active">Research</a></li>
  <li class="nav-item menu-item"><a href="teaching.html" class="nav-link">Teaching</a></li>
  <li class="nav-item menu-item"><a href="https://github.com/qb3" class="nav-link">Github</a></li>
  <li class="nav-item menu-item"><a href="optim_crash_course.html" class="nav-link">Optim&nbsp;Crash&nbsp;Course</a></li>
  </ul>
  </aside>
  <div class="col-12 col-md-9" id="main-content">
  <div class="toptitle">
  <h1>Quentin BERTRAND - Research</h1>
  </div>
<h2>Ph. D. Thesis</h2>
<ul>
<li><p><strong>Q. Bertrand</strong>, <a href="https://tel.archives-ouvertes.fr/tel-03373531/document"  >Hyperparameter selection for high dimensional sparse learning: application to neuroimaging</a>, <a href="./pdfs/slides_defense.pdf"  >slides</a>, <a href="https://youtu.be/-CnX6qtbCYU"  >recording of the defense</a></p>
</li>
</ul>
<h2>Papers</h2>
<ul>
<li><p>2024</p>
<ul>
<li><p>D. Ferbach, <strong>Q. Bertrand</strong>, A. J. Bose, G. Gidel <a href="https://arxiv.org/abs/2407.09499"  >Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences</a>, NeurIPS 2024 (with spotlight!), <a href="./pdfs/iterative_retraining_preference.pdf"  >slides</a></p>
</li>
<li><p><strong>Q. Bertrand</strong>, J. Duque, E. Calvano, G. Gidel <a href="https://arxiv.org/abs/2312.08484"  >Q-learners Can Provably Collude in the Iterated Prisoner's Dilemma</a></p>
</li>
<li><p><strong>Q. Bertrand</strong>, A. J. Bose, A. Duplessis, M. Jiralerspong, G. Gidel <a href="https://arxiv.org/pdf/2310.00429.pdf,"  >On the Stability of Iterative Retraining of Generative Models on their own Data</a>, ICLR 2024 (with spotlight!), <a href="https://github.com/QB3/gen_models_dont_go_mad"  >code</a>, <a href="./pdfs/iterative_retraining.pdf"  >slides</a>, <a href="https://www.youtube.com/watch?v=ZOLHzmSZWrA"  >video</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2023</p>
<ul>
<li><p>J. Ramirez, R. Sukumaran, <strong>Q. Bertrand</strong>, G. Gidel,
<a href="https://arxiv.org/pdf/2306.07905.pdf"  >Omega: Optimistic EMA Gradients</a>, ICML 2023 LatinX in AI Workshop, <a href="https://github.com/juan43ramirez/Omega"  >code</a></p>
</li>
<li><p>S. Lachapelle, T. Deleu, D. Mahajan, I. Mitliagkas, Y. Bengio, S. Lacoste-Julien, <strong>Q. Bertrand</strong>,
<a href="https://arxiv.org/abs/2211.14666"  >Synergies between Disentanglement and Sparsity:
Generalization and Identifiability in Multi-Task Learning</a>, ICML 2023</p>
</li>
<li><p><strong>Q. Bertrand</strong>, W. M. Czarnecki, G. Gidel <a href="https://arxiv.org/pdf/2206.12301.pdf,"  >On the Limitations of Elo: Real-World Games are Transitive, not Additive</a>, AISTATS 2023</p>
</li>
<li><p>Q. Klopfenstein*, <strong>Q. Bertrand</strong>*, A. Gramfort, J. Salmon, S. Vaiter, <a href="https://arxiv.org/abs/2010.11825"  >Model identification and local linear convergence of coordinate descent</a>, Optimization Letters</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2022</p>
<ul>
<li><p>D. Scieur, <strong>Q. Bertrand</strong>, G. Gidel, F. Pedregosa,
<a href="https://arxiv.org/abs/2209.13271"  >The Curse of Unrolling: Rate of Differentiating Through Optimization</a>,
NeurIPS 2022</p>
</li>
<li><p><strong>Q. Bertrand</strong>, Q. Klopfenstein, P.-A. Bannier, G. Gidel, M. Massias <a href="https://arxiv.org/pdf/2204.07826.pdf"  >Beyond L1: Faster and Better Sparse Models with skglm</a>,
NeurIPS 2022
<a href="https://github.com/scikit-learn-contrib/skglm"  >code</a>,
<a href="https://contrib.scikit-learn.org/skglm/"  >doc</a></p>
</li>
<li><p><strong>Q. Bertrand</strong>*, Q. Klopfenstein*, M. Massias, M. Blondel, S. Vaiter, A. Gramfort, J. Salmon,
<a href="https://arxiv.org/abs/2105.01637"  >Implicit differentiation for fast hyperparameter selection in non-smooth convex learning</a>,
JMLR,
<a href="https://github.com/QB3/sparse-ho"  >code</a>,
<a href="https://qb3.github.io/sparse-ho/"  >doc</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2021</p>
<ul>
<li><p>P.-A. Bannier, <strong>Q. Bertrand</strong>, J. Salmon, A. Gramfort,
<a href="https://hal.archives-ouvertes.fr/hal-03418092/document"  >Electromagnetic neural source imaging under
sparsity constraints with SURE-based hyperparameter tuning</a>,
Workshop medical imaging meets NeurIPS, NeurIPS2021,
<a href="https://github.com/PABannier/automatic_hp_selection_for_meg"  >code</a></p>
</li>
<li><p><strong>Q. Bertrand</strong>, M. Massias,
<a href="https://arxiv.org/pdf/2011.10065.pdf"  >Anderson acceleration of coordinate descent</a>,
AISTATS 2021,
<a href="https://github.com/mathurinm/andersoncd"  >code</a>,
<a href="https://mathurinm.github.io/andersoncd/"  >doc</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2020</p>
<ul>
<li><p><strong>Q. Bertrand</strong>*, Q. Klopfenstein*, M. Blondel, S. Vaiter, A. Gramfort, J. Salmon,
<a href="https://arxiv.org/pdf/2002.08943.pdf"  >Implicit differentiation of Lasso-type models for hyperparameter optimization</a>,
ICML 2020,
<a href="https://proceedings.icml.cc/paper/2020/file/e0ab531ec312161511493b002f9be2ee-Paper.pdf"  >proc.</a>,
<a href="https://github.com/QB3/sparse-ho"  >code</a>,
<a href="https://qb3.github.io/sparse-ho/"  >doc</a></p>
</li>
<li><p>M. Massias*, <strong>Q. Bertrand</strong>*, A. Gramfort, J. Salmon,
<a href="https://arxiv.org/abs/2001.05401"  >Support recovery and sup-norm convergence rates for sparse pivotal estimation</a>,
AISTATS 2020,
<a href="http://proceedings.mlr.press/v108/massias20a/massias20a.pdf"  >proc.</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2019</p>
<ul>
<li><p><strong>Q. Bertrand</strong>*, M. Massias*, A. Gramfort, J. Salmon,
<a href="https://arxiv.org/abs/1902.02509"  >Handling correlated and repeated measurements with the smoothed multivariate square-root Lasso</a>, NeurIPS 2019,
<a href="https://papers.nips.cc/paper/8651-handling-correlated-and-repeated-measurements-with-the-smoothed-multivariate-square-root-lasso.pdf"  >proc.</a>,
<a href="https://github.com/QBE/clar"  >code</a>,
<a href="https://qb3.github.io/CLaR/"  >doc</a></p>
</li>
</ul>

</li>
</ul>
<h2>Slides</h2>
<ul>
<li><p><a href="./pdfs/iterative_retraining.pdf"  >On the Stability of Iterative Retraining of Generative Models on their own Data</a>, <a href="https://www.youtube.com/watch?v=ZOLHzmSZWrA"  >video</a></p>
</li>
<li><p><a href="./pdfs/slides_defense.pdf"  >Hyperparameter selection for high dimensional sparse learning: application to neuroimaging</a>,
28/09/2021, Ph. D. Defense, Paris-Saclay, France.</p>
</li>
<li><p><a href="./pdfs/talks/cd.pdf"  >Anderson acceleration of coordinate descent</a>,
07/06/2021, Journées des statistiques, Nice, France.</p>
</li>
<li><p><a href="./pdfs/talks/DS3_slides.pdf"  >Optimization for machine learning, &ldquo;Hands on&rdquo;</a>,
04/01/2021, Data Science Summer School of École polytechnique, France.</p>
</li>
<li><p><a href="./pdfs/talks/sparse_ho_long.pdf"  >Implicit differentiation of Lasso-type models for hyperparameter optimization</a>,
09/09/2020, SMAI MODE 2020, France.</p>
</li>
<li><p><a href="./pdfs/talks/GDRMOA2019.pdf"  >Handling correlated and repeated measurements with the smoothed multivariate square-root Lasso</a>,
18/10/2019, GDR MOA 2019, France.</p>
</li>
</ul>
<h2>Reviewing service</h2>
<ul>
<li><p>ICML 2021-2024</p>
</li>
<li><p>ICLR 2021-2024</p>
</li>
<li><p>NeurIPS 2020-2024 (top reviewer in 2021 and 2022)</p>
</li>
<li><p>JMLR 2021-2024</p>
</li>
<li><p>Neuroimage 2019-2021</p>
</li>
<li><p>AISTATS 2021</p>
</li>
<li><p>Electronic Journal of Statistics 2020</p>
</li>
<li><p>IEEE SPL 2020</p>
</li>
</ul>
  <!-- End of main body -->
  </div>
  </div>
  </main>
  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  </body>
  </html>
